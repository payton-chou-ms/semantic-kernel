# Copyright (c) Microsoft. All rights reserved.

import asyncio

import chainlit as cl
from azure.identity.aio import DefaultAzureCredential

from semantic_kernel.agents import (
    Agent,
    AzureAIAgent,
    AzureAIAgentSettings,
    ConcurrentOrchestration,
)
from semantic_kernel.agents.runtime import InProcessRuntime

"""
The following sample demonstrates how to create a concurrent orchestration for
executing multiple Azure AI agents on the same task in parallel with Chainlit UI.

This sample demonstrates the basic steps of creating and starting a runtime, creating
Azure AI agents using the Azure AI Agent service, creating a concurrent orchestration 
with these agents, invoking the orchestration through a web interface, and displaying
the results.
"""

# Global variables to store agents and runtime
agents_cache = None
runtime_cache = None
client_cache = None
creds_cache = None


async def get_agents(client) -> list[Agent]:
    """Return a list of Azure AI agents that will participate in the concurrent orchestration.

    Feel free to add or remove agents.
    """
    # Create physics expert agent in Azure AI Agent service
    physics_agent_definition = await client.agents.create_agent(
        model=AzureAIAgentSettings().model_deployment_name,
        name="PhysicsExpert",
        instructions="You are an expert in physics. You answer questions from a physics perspective.",
    )
    physics_agent = AzureAIAgent(
        client=client,
        definition=physics_agent_definition,
    )

    # Create chemistry expert agent in Azure AI Agent service
    chemistry_agent_definition = await client.agents.create_agent(
        model=AzureAIAgentSettings().model_deployment_name,
        name="ChemistryExpert",
        instructions="You are an expert in chemistry. You answer questions from a chemistry perspective.",
    )
    chemistry_agent = AzureAIAgent(
        client=client,
        definition=chemistry_agent_definition,
    )

    return [physics_agent, chemistry_agent]


@cl.on_chat_start
async def on_chat_start():
    """Initialize the agents and runtime when a new chat session starts."""
    global agents_cache, runtime_cache, client_cache, creds_cache

    await cl.Message(content="ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Azure AI ä»£ç†ç¨‹å¼...").send()

    try:
        # Initialize Azure credentials and client
        creds_cache = DefaultAzureCredential()
        client_cache = AzureAIAgent.create_client(credential=creds_cache)

        # Create Azure AI agents
        agents_cache = await get_agents(client_cache)

        # Create and start runtime
        runtime_cache = InProcessRuntime()
        runtime_cache.start()

        # Store in user session
        cl.user_session.set("agents", agents_cache)
        cl.user_session.set("runtime", runtime_cache)
        cl.user_session.set("client", client_cache)
        cl.user_session.set("creds", creds_cache)

        await cl.Message(
            content="âœ… ä»£ç†ç¨‹å¼å·²æˆåŠŸåˆå§‹åŒ–ï¼\n\n"
            "ğŸ§ª **å¯ç”¨çš„å°ˆå®¶ä»£ç†ç¨‹å¼ï¼š**\n"
            "- ğŸ”¬ PhysicsExpert - ç‰©ç†å­¸å°ˆå®¶\n"
            "- âš—ï¸ ChemistryExpert - åŒ–å­¸å°ˆå®¶\n\n"
            "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œå…©ä½å°ˆå®¶æœƒåŒæ™‚å›ç­”ï¼"
        ).send()

    except Exception as e:
        await cl.Message(content=f"âŒ åˆå§‹åŒ–å¤±æ•—: {str(e)}").send()


@cl.on_message
async def on_message(message: cl.Message):
    """Handle incoming messages and process them with the concurrent orchestration."""
    agents = cl.user_session.get("agents")
    runtime = cl.user_session.get("runtime")

    if not agents or not runtime:
        await cl.Message(content="âŒ ä»£ç†ç¨‹å¼æœªåˆå§‹åŒ–ï¼Œè«‹é‡æ–°æ•´ç†é é¢ã€‚").send()
        return

    # Show processing message
    processing_msg = cl.Message(content="ğŸ¤” å°ˆå®¶å€‘æ­£åœ¨æ€è€ƒæ‚¨çš„å•é¡Œ...")
    await processing_msg.send()

    try:
        # Create concurrent orchestration
        concurrent_orchestration = ConcurrentOrchestration(members=agents)

        # Invoke the orchestration
        orchestration_result = await concurrent_orchestration.invoke(
            task=message.content,
            runtime=runtime,
        )

        # Wait for results with timeout
        results = await orchestration_result.get(timeout=30)

        # Update processing message
        await processing_msg.remove()

        # Display results from each agent
        response_content = "## å°ˆå®¶å›æ‡‰\n\n"

        for i, result in enumerate(results):
            icon = "ğŸ”¬" if "Physics" in result.name else "âš—ï¸"
            response_content += (
                f"### {icon} {result.name}\n\n{result.content}\n\n---\n\n"
            )

        await cl.Message(content=response_content).send()

    except asyncio.TimeoutError:
        await processing_msg.remove()
        await cl.Message(content="â° è«‹æ±‚è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚").send()
    except Exception as e:
        await processing_msg.remove()
        await cl.Message(content=f"âŒ è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}").send()


@cl.on_chat_end
async def on_chat_end():
    """Clean up resources when chat session ends."""
    agents = cl.user_session.get("agents")
    runtime = cl.user_session.get("runtime")
    client = cl.user_session.get("client")
    creds = cl.user_session.get("creds")

    try:
        if runtime:
            await runtime.stop_when_idle()

        if agents and client:
            for agent in agents:
                try:
                    await client.agents.delete_agent(agent.id)
                except Exception:
                    pass  # Ignore cleanup errors

        if client:
            await client.close()

        if creds:
            await creds.close()

    except Exception as e:
        print(f"æ¸…ç†è³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    """
    ç¯„ä¾‹ä½¿ç”¨æ–¹å¼ï¼š
    1. å®‰è£ chainlit: pip install chainlit
    2. åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼: chainlit run step1_concurrent_ui.py
    3. åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿ http://localhost:8000
    4. é–‹å§‹èˆ‡å¤šå€‹ AI å°ˆå®¶å°è©±ï¼
    
    ç¯„ä¾‹å•é¡Œï¼š
    - "What is temperature?"
    - "Explain photosynthesis"
    - "How does gravity work?"
    """


# For command line execution (optional)
if __name__ == "__main__":
    print("è«‹ä½¿ç”¨ 'chainlit run step1_concurrent_ui.py' ä¾†å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼")
